{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Topic_Modeling_Using_Gensim_Latent_Dirichlet_Allocation(LDA).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Mount the Google Drive"
      ],
      "metadata": {
        "id": "emDNEAFGTjU5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X6iAskymTfSf",
        "outputId": "fd54965e-7a1f-4c81-d8b4-c97b5153e2f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m pip install --upgrade pip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dCOU2alJTljI",
        "outputId": "b35c33ac-bd22-406a-db88-cd2ebe4f0be2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (22.2.2)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m pip install --user spacy==3.1.3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VGspWqxcTlgv",
        "outputId": "f43ae4b3-8f0e-4734-f285-1b5dad236a75"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: spacy==3.1.3 in /root/.local/lib/python3.7/site-packages (3.1.3)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy==3.1.3) (3.0.6)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /usr/local/lib/python3.7/dist-packages (from spacy==3.1.3) (2.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3.1.3) (21.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /root/.local/lib/python3.7/site-packages (from spacy==3.1.3) (1.8.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy==3.1.3) (57.4.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy==3.1.3) (0.10.1)\n",
            "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3.1.3) (0.4.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3.1.3) (0.7.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy==3.1.3) (2.0.8)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy==3.1.3) (0.6.2)\n",
            "Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4 in /root/.local/lib/python3.7/site-packages (from spacy==3.1.3) (3.10.0.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3.1.3) (4.64.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /usr/local/lib/python3.7/dist-packages (from spacy==3.1.3) (3.0.9)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy==3.1.3) (2.0.6)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3.1.3) (1.0.7)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3.1.3) (2.23.0)\n",
            "Requirement already satisfied: thinc<8.1.0,>=8.0.9 in /root/.local/lib/python3.7/site-packages (from spacy==3.1.3) (8.0.17)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy==3.1.3) (2.11.3)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3.1.3) (1.21.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy==3.1.3) (3.8.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy==3.1.3) (3.0.9)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy==3.1.3) (5.2.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.1.3) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.1.3) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.1.3) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.1.3) (2022.6.15)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy==3.1.3) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy==3.1.3) (2.0.1)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Import the required libraries"
      ],
      "metadata": {
        "id": "2EkmJUQSTt99"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m pip install gensim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4QLW-lxzTw80",
        "outputId": "e74c71d1-be3a-4dee-fa56-383d91a1e0e7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (3.6.0)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.15.0)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (5.2.1)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.21.6)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.7.3)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import spacy\n",
        "\n",
        "import nltk\n",
        "nltk.download(\"popular\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TVIyVQO3Tlev",
        "outputId": "f07615f4-e415-4ab4-9f06-810a793db8f6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading collection 'popular'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Package cmudict is already up-to-date!\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Package genesis is already up-to-date!\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Package inaugural is already up-to-date!\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Package names is already up-to-date!\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Package stopwords is already up-to-date!\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Package treebank is already up-to-date!\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package twitter_samples is already up-to-date!\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    |   Package omw is already up-to-date!\n",
            "[nltk_data]    | Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]    |   Package omw-1.4 is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet2021 to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet2021 is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet31 to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet31 is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Package words is already up-to-date!\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Package punkt is already up-to-date!\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package snowball_data is already up-to-date!\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
            "[nltk_data]    |       to-date!\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection popular\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords \n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "import string\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import gensim\n",
        "from gensim import corpora\n",
        "\n",
        "from warnings import filterwarnings\n",
        "filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "QxUMA067VhKM"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download en_core_web_sm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "da9Of4pjTlcf",
        "outputId": "b4f16c3c-25df-4ecb-eae5-6e61d2132eea"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting en-core-web-sm==3.1.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.1.0/en_core_web_sm-3.1.0-py3-none-any.whl (13.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.6/13.6 MB\u001b[0m \u001b[31m54.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.2.0,>=3.1.0 in /root/.local/lib/python3.7/site-packages (from en-core-web-sm==3.1.0) (3.1.3)\n",
            "Requirement already satisfied: thinc<8.1.0,>=8.0.9 in /root/.local/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (8.0.17)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (3.0.6)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (3.0.9)\n",
            "Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4 in /root/.local/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (3.10.0.2)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.0.6)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (0.6.2)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /root/.local/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (1.8.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (21.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.11.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.4.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (0.7.8)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (1.0.7)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (57.4.0)\n",
            "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (0.4.2)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (0.10.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (1.21.6)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.0.8)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.23.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (4.64.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (3.8.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (3.0.9)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (5.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (1.24.3)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.0.1)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load('en_core_web_sm')"
      ],
      "metadata": {
        "id": "RjrcfQjDTlaX"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "D1 = 'I want to watch a movie this weekend.'\n",
        "D2 =  'I went shopping yesterday. New Zealand won the World Test Championship by beating India by eight wickets at Southampton.'\n",
        "D3 =  'I don’t watch cricket. Netflix and Amazon Prime have very good movies to watch.'\n",
        "D4 =  'Movies are a nice way to chill however, this time I would like to paint and read some good books. It’s been long!'\n",
        "D5 =  'This blueberry milkshake is so good! Try reading Dr. Joe Dispenza’s books. His work is such a game-changer! His books helped to learn so much about how our thoughts impact our biology and how we can all rewire our brains.'\n",
        "print ('D1: ',D1,'\\nD2: ',D2,'\\nD3: ',D3,'\\nD4: ',D4,'\\nD5: ',D5, end = \"\\n\",)\n",
        "# Combine all the documents into a list:\n",
        "corpus = [D1, D2, D3, D4, D5]\n",
        "print( \"Corpus: \", corpus)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Zn3BPQCTlTv",
        "outputId": "5fe8c154-cb5c-4833-d183-7640d3bfbdaf"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "D1:  I want to watch a movie this weekend. \n",
            "D2:  I went shopping yesterday. New Zealand won the World Test Championship by beating India by eight wickets at Southampton. \n",
            "D3:  I don’t watch cricket. Netflix and Amazon Prime have very good movies to watch. \n",
            "D4:  Movies are a nice way to chill however, this time I would like to paint and read some good books. It’s been long! \n",
            "D5:  This blueberry milkshake is so good! Try reading Dr. Joe Dispenza’s books. His work is such a game-changer! His books helped to learn so much about how our thoughts impact our biology and how we can all rewire our brains.\n",
            "Corpus:  ['I want to watch a movie this weekend.', 'I went shopping yesterday. New Zealand won the World Test Championship by beating India by eight wickets at Southampton.', 'I don’t watch cricket. Netflix and Amazon Prime have very good movies to watch.', 'Movies are a nice way to chill however, this time I would like to paint and read some good books. It’s been long!', 'This blueberry milkshake is so good! Try reading Dr. Joe Dispenza’s books. His work is such a game-changer! His books helped to learn so much about how our thoughts impact our biology and how we can all rewire our brains.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Text Preprocessing"
      ],
      "metadata": {
        "id": "z049a-wXUB5k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stop_loss_words = set(stopwords.words('english'))\n",
        "exclude = set(string.punctuation)\n",
        "lemma = WordNetLemmatizer()\n",
        "\n",
        "\n",
        "def clean_data(doc):\n",
        "  # Convert text into lower case and split into words\n",
        "  stop_free_word = \" \".join([i for i in doc.lower().split() if i not in stop_loss_words])\n",
        "\n",
        "  # Remove stop words if present\n",
        "  remove_stop_words = ''.join(ch for ch in stop_free_word if ch not in exclude)  \n",
        "\n",
        "  # Remove punctuations, symbols and special characters and normalize the text\n",
        "  normalize_text = \" \".join(lemma.lemmatize(word) for word in remove_stop_words.split())  \n",
        "  return normalize_text\n",
        "\n",
        "# Clean data is stored in a new list\n",
        "clean_corpus = [clean_data(doc).split() for doc in corpus]\n",
        "print(\"Clean corpus: \", clean_corpus)"
      ],
      "metadata": {
        "id": "oTlm8MhrTlRP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03605a54-17aa-4386-ce7a-a8138d032e52"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Clean corpus:  [['want', 'watch', 'movie', 'weekend'], ['went', 'shopping', 'yesterday', 'new', 'zealand', 'world', 'test', 'championship', 'beating', 'india', 'eight', 'wicket', 'southampton'], ['don’t', 'watch', 'cricket', 'netflix', 'amazon', 'prime', 'good', 'movie', 'watch'], ['movie', 'nice', 'way', 'chill', 'however', 'time', 'would', 'like', 'paint', 'read', 'good', 'book', 'it’s', 'long'], ['blueberry', 'milkshake', 'good', 'try', 'reading', 'dr', 'joe', 'dispenza’s', 'book', 'work', 'gamechanger', 'book', 'helped', 'learn', 'much', 'thought', 'impact', 'biology', 'rewire', 'brain']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Creating Document Term Matrix"
      ],
      "metadata": {
        "id": "Pgg5P_zAUTkb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dict_ = corpora.Dictionary(clean_corpus)\n",
        "print(dict_)"
      ],
      "metadata": {
        "id": "GvDSIvDQUNht",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74ec3c52-0785-4ac1-94ca-7098d74808e3"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dictionary(52 unique tokens: ['movie', 'want', 'watch', 'weekend', 'beating']...)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for a in dict_.values():\n",
        "  print(a)"
      ],
      "metadata": {
        "id": "1Irfl3sdUNfM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa6802fd-c23e-4093-e4a4-3ff4ade85ed5"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "movie\n",
            "want\n",
            "watch\n",
            "weekend\n",
            "beating\n",
            "championship\n",
            "eight\n",
            "india\n",
            "new\n",
            "shopping\n",
            "southampton\n",
            "test\n",
            "went\n",
            "wicket\n",
            "world\n",
            "yesterday\n",
            "zealand\n",
            "amazon\n",
            "cricket\n",
            "don’t\n",
            "good\n",
            "netflix\n",
            "prime\n",
            "book\n",
            "chill\n",
            "however\n",
            "it’s\n",
            "like\n",
            "long\n",
            "nice\n",
            "paint\n",
            "read\n",
            "time\n",
            "way\n",
            "would\n",
            "biology\n",
            "blueberry\n",
            "brain\n",
            "dispenza’s\n",
            "dr\n",
            "gamechanger\n",
            "helped\n",
            "impact\n",
            "joe\n",
            "learn\n",
            "milkshake\n",
            "much\n",
            "reading\n",
            "rewire\n",
            "thought\n",
            "try\n",
            "work\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting the corpus into Document Term Matrix using the dictionary \n",
        "document_term_matrix = [dict_.doc2bow(i) for i in clean_corpus]\n",
        "document_term_matrix"
      ],
      "metadata": {
        "id": "Q2k_zmlRUNcr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb64baf5-473a-4661-b9c1-ec83bb2e7409"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[(0, 1), (1, 1), (2, 1), (3, 1)],\n",
              " [(4, 1),\n",
              "  (5, 1),\n",
              "  (6, 1),\n",
              "  (7, 1),\n",
              "  (8, 1),\n",
              "  (9, 1),\n",
              "  (10, 1),\n",
              "  (11, 1),\n",
              "  (12, 1),\n",
              "  (13, 1),\n",
              "  (14, 1),\n",
              "  (15, 1),\n",
              "  (16, 1)],\n",
              " [(0, 1), (2, 2), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1)],\n",
              " [(0, 1),\n",
              "  (20, 1),\n",
              "  (23, 1),\n",
              "  (24, 1),\n",
              "  (25, 1),\n",
              "  (26, 1),\n",
              "  (27, 1),\n",
              "  (28, 1),\n",
              "  (29, 1),\n",
              "  (30, 1),\n",
              "  (31, 1),\n",
              "  (32, 1),\n",
              "  (33, 1),\n",
              "  (34, 1)],\n",
              " [(20, 1),\n",
              "  (23, 2),\n",
              "  (35, 1),\n",
              "  (36, 1),\n",
              "  (37, 1),\n",
              "  (38, 1),\n",
              "  (39, 1),\n",
              "  (40, 1),\n",
              "  (41, 1),\n",
              "  (42, 1),\n",
              "  (43, 1),\n",
              "  (44, 1),\n",
              "  (45, 1),\n",
              "  (46, 1),\n",
              "  (47, 1),\n",
              "  (48, 1),\n",
              "  (49, 1),\n",
              "  (50, 1),\n",
              "  (51, 1)]]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. LDA Algorithm"
      ],
      "metadata": {
        "id": "65RHUFHRUmXk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lda_algorithm = gensim.models.ldamodel.LdaModel"
      ],
      "metadata": {
        "id": "m1ewNzo8UNZ8"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ldamodel = lda_algorithm(document_term_matrix, num_topics=6, \n",
        "                         id2word = dict_, passes=1, random_state=0, eval_every=None)\n"
      ],
      "metadata": {
        "id": "eKWQ1N-NUNXT"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ldamodel.print_topics()"
      ],
      "metadata": {
        "id": "YanR3fmbUNU0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "281fa3e2-8133-40fe-b7e8-18324f7ca699"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0,\n",
              "  '0.136*\"watch\" + 0.084*\"movie\" + 0.060*\"good\" + 0.060*\"amazon\" + 0.060*\"netflix\" + 0.060*\"prime\" + 0.060*\"cricket\" + 0.060*\"don’t\" + 0.029*\"want\" + 0.027*\"weekend\"'),\n",
              " (1,\n",
              "  '0.074*\"weekend\" + 0.070*\"want\" + 0.065*\"movie\" + 0.063*\"watch\" + 0.015*\"don’t\" + 0.015*\"good\" + 0.015*\"book\" + 0.015*\"cricket\" + 0.015*\"prime\" + 0.015*\"new\"'),\n",
              " (2,\n",
              "  '0.052*\"book\" + 0.028*\"good\" + 0.028*\"blueberry\" + 0.028*\"try\" + 0.028*\"helped\" + 0.028*\"reading\" + 0.028*\"joe\" + 0.028*\"work\" + 0.028*\"dispenza’s\" + 0.028*\"thought\"'),\n",
              " (3,\n",
              "  '0.020*\"championship\" + 0.020*\"wicket\" + 0.020*\"southampton\" + 0.020*\"yesterday\" + 0.020*\"went\" + 0.020*\"india\" + 0.020*\"shopping\" + 0.020*\"new\" + 0.020*\"world\" + 0.020*\"zealand\"'),\n",
              " (4,\n",
              "  '0.051*\"movie\" + 0.051*\"book\" + 0.051*\"paint\" + 0.051*\"long\" + 0.051*\"like\" + 0.051*\"read\" + 0.051*\"time\" + 0.051*\"chill\" + 0.051*\"would\" + 0.051*\"however\"'),\n",
              " (5,\n",
              "  '0.019*\"weekend\" + 0.019*\"watch\" + 0.019*\"movie\" + 0.019*\"good\" + 0.019*\"want\" + 0.019*\"don’t\" + 0.019*\"book\" + 0.019*\"cricket\" + 0.019*\"prime\" + 0.019*\"new\"')]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.1) Extracting Topics from the Corpus"
      ],
      "metadata": {
        "id": "B7xi05ZCU4fq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(ldamodel.print_topics(num_topics=6, num_words=5))"
      ],
      "metadata": {
        "id": "6QsKhnNRUNSD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba94f115-aebd-4bfb-bdb4-fe477c9e0085"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(0, '0.136*\"watch\" + 0.084*\"movie\" + 0.060*\"good\" + 0.060*\"amazon\" + 0.060*\"netflix\"'), (1, '0.074*\"weekend\" + 0.070*\"want\" + 0.065*\"movie\" + 0.063*\"watch\" + 0.015*\"don’t\"'), (2, '0.052*\"book\" + 0.028*\"good\" + 0.028*\"blueberry\" + 0.028*\"try\" + 0.028*\"helped\"'), (3, '0.020*\"championship\" + 0.020*\"wicket\" + 0.020*\"southampton\" + 0.020*\"yesterday\" + 0.020*\"went\"'), (4, '0.051*\"movie\" + 0.051*\"book\" + 0.051*\"paint\" + 0.051*\"long\" + 0.051*\"like\"'), (5, '0.019*\"weekend\" + 0.019*\"watch\" + 0.019*\"movie\" + 0.019*\"good\" + 0.019*\"want\"')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.2) Assigning the topics to the documents"
      ],
      "metadata": {
        "id": "oDSuvfitVAZp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "counter = 0\n",
        "for i in ldamodel[document_term_matrix]:\n",
        "  print(\"Document : \", counter, i)\n",
        "  counter += 1"
      ],
      "metadata": {
        "id": "1yNN_oVeVEOG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b984d41-dbf8-42c7-b46f-89dfadaaf1fc"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Document :  0 [(0, 0.2822866), (1, 0.5842826), (2, 0.03333387), (3, 0.033336017), (4, 0.03342482), (5, 0.03333605)]\n",
            "Document :  1 [(0, 0.011905481), (1, 0.011906071), (2, 0.94046956), (3, 0.011907104), (4, 0.011905371), (5, 0.011906449)]\n",
            "Document :  2 [(0, 0.91660607), (1, 0.016687103), (2, 0.016676264), (3, 0.016667519), (4, 0.016695492), (5, 0.016667534)]\n",
            "Document :  3 [(0, 0.011138659), (1, 0.011119502), (2, 0.011127129), (3, 0.011111923), (4, 0.9443909), (5, 0.011111934)]\n",
            "Document :  4 [(2, 0.9602895)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "jG4AA3qXbyPH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}