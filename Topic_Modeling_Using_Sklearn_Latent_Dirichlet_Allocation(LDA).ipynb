{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Topic_Modeling_Using_Sklearn_Latent_Dirichlet_Allocation(LDA).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Mount the Google Drive"
      ],
      "metadata": {
        "id": "VwEsVeKwK6tQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7MkjPtqfK6OQ",
        "outputId": "ee9f747f-de60-4b61-bb22-c53b1b012a5f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m pip install --upgrade pip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "20M9UuxqS11l",
        "outputId": "d1da53cf-4068-4094-dc54-0bf8dc2f75f4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (22.2.2)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m pip install --user spacy==3.1.3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nd2avvbhLG2h",
        "outputId": "616143b3-d3a9-4331-e1f4-a23de031e6cf"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: spacy==3.1.3 in /root/.local/lib/python3.7/site-packages (3.1.3)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /usr/local/lib/python3.7/dist-packages (from spacy==3.1.3) (3.0.9)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /root/.local/lib/python3.7/site-packages (from spacy==3.1.3) (1.8.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy==3.1.3) (2.11.3)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy==3.1.3) (0.6.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3.1.3) (0.7.8)\n",
            "Requirement already satisfied: thinc<8.1.0,>=8.0.9 in /root/.local/lib/python3.7/site-packages (from spacy==3.1.3) (8.0.17)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy==3.1.3) (2.0.6)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy==3.1.3) (2.0.8)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /usr/local/lib/python3.7/dist-packages (from spacy==3.1.3) (2.4.4)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3.1.3) (1.0.7)\n",
            "Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4 in /root/.local/lib/python3.7/site-packages (from spacy==3.1.3) (3.10.0.2)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy==3.1.3) (0.10.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3.1.3) (4.64.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3.1.3) (1.21.6)\n",
            "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3.1.3) (0.4.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3.1.3) (21.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy==3.1.3) (57.4.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3.1.3) (2.23.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy==3.1.3) (3.0.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy==3.1.3) (3.8.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy==3.1.3) (3.0.9)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy==3.1.3) (5.2.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.1.3) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.1.3) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.1.3) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.1.3) (2022.6.15)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy==3.1.3) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy==3.1.3) (2.0.1)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Import the required libraries"
      ],
      "metadata": {
        "id": "smGvs4ZBLM0e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import spacy"
      ],
      "metadata": {
        "id": "4EIjI65PLLJN"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U wn==0.0.22"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2lCx764nMaeI",
        "outputId": "8bdeae82-8236-4eb0-96cd-cced856214a9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: wn==0.0.22 in /usr/local/lib/python3.7/dist-packages (0.0.22)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip show nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ys3FB28qM1H4",
        "outputId": "9e188dcf-5643-477b-cc27-518c68308b5b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: nltk\n",
            "Version: 3.7\n",
            "Summary: Natural Language Toolkit\n",
            "Home-page: https://www.nltk.org/\n",
            "Author: NLTK Team\n",
            "Author-email: nltk.team@gmail.com\n",
            "License: Apache License, Version 2.0\n",
            "Location: /usr/local/lib/python3.7/dist-packages\n",
            "Requires: click, joblib, regex, tqdm\n",
            "Required-by: textblob\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OcGBhzRFNA74",
        "outputId": "ac8e5a29-875b-4fbf-a3f1-f60f7d11fc3b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.7.13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download(\"popular\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rlOMBWyEVaGj",
        "outputId": "c7e1557e-e5fc-4c33-a816-e5508d3a6536"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading collection 'popular'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Package cmudict is already up-to-date!\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Package genesis is already up-to-date!\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Package inaugural is already up-to-date!\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Package names is already up-to-date!\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Package stopwords is already up-to-date!\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Package treebank is already up-to-date!\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package twitter_samples is already up-to-date!\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    |   Package omw is already up-to-date!\n",
            "[nltk_data]    | Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]    |   Package omw-1.4 is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet2021 to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet2021 is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet31 to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet31 is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Package words is already up-to-date!\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Package punkt is already up-to-date!\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package snowball_data is already up-to-date!\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
            "[nltk_data]    |       to-date!\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection popular\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "import string\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "import numpy as np\n",
        "import pandas as pandas\n",
        "\n",
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "\n",
        "from warnings import filterwarnings\n",
        "filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "edPyniZuLZaK"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download en_core_web_sm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "shNATplyNSjI",
        "outputId": "276f22f5-3051-4451-9004-414c8e4ca6c4"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting en-core-web-sm==3.1.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.1.0/en_core_web_sm-3.1.0-py3-none-any.whl (13.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.6/13.6 MB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.2.0,>=3.1.0 in /root/.local/lib/python3.7/site-packages (from en-core-web-sm==3.1.0) (3.1.3)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (0.7.8)\n",
            "Requirement already satisfied: thinc<8.1.0,>=8.0.9 in /root/.local/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (8.0.17)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (0.10.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.0.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (21.3)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (1.0.7)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (3.0.6)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.4.4)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (4.64.0)\n",
            "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (0.4.2)\n",
            "Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4 in /root/.local/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (3.10.0.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.11.3)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (0.6.2)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.0.6)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (1.21.6)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /root/.local/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (1.8.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.23.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (57.4.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (3.8.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (3.0.9)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (5.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2022.6.15)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (3.0.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.0.1)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp=spacy.load('en_core_web_sm')"
      ],
      "metadata": {
        "id": "_k8hWP_LLnc6"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "D1 = 'I want to watch a movie this weekend.'\n",
        "D2 =  'I went shopping yesterday. New Zealand won the World Test Championship by beating India by eight wickets at Southampton.'\n",
        "D3 =  'I don’t watch cricket. Netflix and Amazon Prime have very good movies to watch.'\n",
        "D4 =  'Movies are a nice way to chill however, this time I would like to paint and read some good books. It’s been long!'\n",
        "D5 =  'This blueberry milkshake is so good! Try reading Dr. Joe Dispenza’s books. His work is such a game-changer! His books helped to learn so much about how our thoughts impact our biology and how we can all rewire our brains.'\n",
        "print ('D1: ',D1,'\\nD2: ',D2,'\\nD3: ',D3,'\\nD4: ',D4,'\\nD5: ',D5, end = \"\\n\",)\n",
        "\n",
        "# Combine all the documents into a list:\n",
        "corpus = [D1, D2, D3, D4, D5]\n",
        "print( \"Corpus: \", corpus)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8HlL_4l-NQWF",
        "outputId": "6f149a32-fd2b-48e1-d0a6-768897acd2cc"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "D1:  I want to watch a movie this weekend. \n",
            "D2:  I went shopping yesterday. New Zealand won the World Test Championship by beating India by eight wickets at Southampton. \n",
            "D3:  I don’t watch cricket. Netflix and Amazon Prime have very good movies to watch. \n",
            "D4:  Movies are a nice way to chill however, this time I would like to paint and read some good books. It’s been long! \n",
            "D5:  This blueberry milkshake is so good! Try reading Dr. Joe Dispenza’s books. His work is such a game-changer! His books helped to learn so much about how our thoughts impact our biology and how we can all rewire our brains.\n",
            "Corpus:  ['I want to watch a movie this weekend.', 'I went shopping yesterday. New Zealand won the World Test Championship by beating India by eight wickets at Southampton.', 'I don’t watch cricket. Netflix and Amazon Prime have very good movies to watch.', 'Movies are a nice way to chill however, this time I would like to paint and read some good books. It’s been long!', 'This blueberry milkshake is so good! Try reading Dr. Joe Dispenza’s books. His work is such a game-changer! His books helped to learn so much about how our thoughts impact our biology and how we can all rewire our brains.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Text Preprocessing"
      ],
      "metadata": {
        "id": "Q0o9XUy8NnlM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stop_loss_words = set(stopwords.words('english'))\n",
        "exclude = set(string.punctuation)\n",
        "lemma = WordNetLemmatizer()\n",
        "\n",
        "\n",
        "def clean_data(doc):\n",
        "  # Convert text into lower case and split into words\n",
        "  stop_free_word = \" \".join([i for i in doc.lower().split() if i not in stop_loss_words])\n",
        "\n",
        "  # Remove stop words if present\n",
        "  remove_stop_words = ''.join(ch for ch in stop_free_word if ch not in exclude)  \n",
        "\n",
        "  # Remove punctuations, symbols and special characters and normalize the text\n",
        "  normalize_text = \" \".join(lemma.lemmatize(word) for word in remove_stop_words.split())  \n",
        "  return normalize_text\n",
        "\n",
        "# Clean data is stored in a new list\n",
        "clean_corpus = [clean_data(doc).split() for doc in corpus]\n",
        "print(\"Clean corpus: \", clean_corpus)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WqmXokh9NlvB",
        "outputId": "f4102c8b-cfd5-4878-f1e1-6875e01a8b04"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Clean corpus:  [['want', 'watch', 'movie', 'weekend'], ['went', 'shopping', 'yesterday', 'new', 'zealand', 'world', 'test', 'championship', 'beating', 'india', 'eight', 'wicket', 'southampton'], ['don’t', 'watch', 'cricket', 'netflix', 'amazon', 'prime', 'good', 'movie', 'watch'], ['movie', 'nice', 'way', 'chill', 'however', 'time', 'would', 'like', 'paint', 'read', 'good', 'book', 'it’s', 'long'], ['blueberry', 'milkshake', 'good', 'try', 'reading', 'dr', 'joe', 'dispenza’s', 'book', 'work', 'gamechanger', 'book', 'helped', 'learn', 'much', 'thought', 'impact', 'biology', 'rewire', 'brain']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Convert Text into Numerical Representation"
      ],
      "metadata": {
        "id": "mO0e0K0eOptx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting text into numerical representation using tf-idf vectorizer\n",
        "tf_idf_vectorizer = TfidfVectorizer(tokenizer=lambda doc: doc, lowercase=False) \n",
        "print('TF-IDF Vectorizer: ',tf_idf_vectorizer)\n",
        "# Converting text into numerical representation using count vectorizer\n",
        "cv_vectorizer = CountVectorizer(tokenizer=lambda doc: doc, lowercase=False)\n",
        "print('Count Vectorizer: ',cv_vectorizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P8PDQCgiOhge",
        "outputId": "cf965ad5-bb34-441a-d9b8-c1edf846916e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF-IDF Vectorizer:  TfidfVectorizer(lowercase=False,\n",
            "                tokenizer=<function <lambda> at 0x7f68e2033950>)\n",
            "Count Vectorizer:  CountVectorizer(lowercase=False,\n",
            "                tokenizer=<function <lambda> at 0x7f68e68437a0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Array from TF-IDF Vectorizer \n",
        "tf_idf_array = tf_idf_vectorizer.fit_transform(clean_corpus)\n",
        "print(tf_idf_array)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0SxjCZ9JO24O",
        "outputId": "e03ef512-d3f2-4f70-ff7c-220a03e02ab0"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  (0, 44)\t0.5680140774328015\n",
            "  (0, 25)\t0.38040564760664297\n",
            "  (0, 42)\t0.45827018116532225\n",
            "  (0, 41)\t0.5680140774328015\n",
            "  (1, 36)\t0.2773500981126146\n",
            "  (1, 46)\t0.2773500981126146\n",
            "  (1, 12)\t0.2773500981126146\n",
            "  (1, 18)\t0.2773500981126146\n",
            "  (1, 1)\t0.2773500981126146\n",
            "  (1, 6)\t0.2773500981126146\n",
            "  (1, 37)\t0.2773500981126146\n",
            "  (1, 48)\t0.2773500981126146\n",
            "  (1, 51)\t0.2773500981126146\n",
            "  (1, 28)\t0.2773500981126146\n",
            "  (1, 50)\t0.2773500981126146\n",
            "  (1, 35)\t0.2773500981126146\n",
            "  (1, 45)\t0.2773500981126146\n",
            "  (2, 14)\t0.22969985625059522\n",
            "  (2, 31)\t0.34298321477483373\n",
            "  (2, 0)\t0.34298321477483373\n",
            "  (2, 27)\t0.34298321477483373\n",
            "  (2, 8)\t0.34298321477483373\n",
            "  (2, 10)\t0.34298321477483373\n",
            "  (2, 25)\t0.22969985625059522\n",
            "  (2, 42)\t0.5534333961648077\n",
            "  :\t:\n",
            "  (3, 16)\t0.2823018492676415\n",
            "  (3, 7)\t0.2823018492676415\n",
            "  (3, 43)\t0.2823018492676415\n",
            "  (3, 29)\t0.2823018492676415\n",
            "  (3, 14)\t0.18906083855626746\n",
            "  (3, 25)\t0.18906083855626746\n",
            "  (4, 5)\t0.22331568324278164\n",
            "  (4, 34)\t0.22331568324278164\n",
            "  (4, 2)\t0.22331568324278164\n",
            "  (4, 17)\t0.22331568324278164\n",
            "  (4, 38)\t0.22331568324278164\n",
            "  (4, 26)\t0.22331568324278164\n",
            "  (4, 21)\t0.22331568324278164\n",
            "  (4, 15)\t0.22331568324278164\n",
            "  (4, 13)\t0.22331568324278164\n",
            "  (4, 47)\t0.22331568324278164\n",
            "  (4, 9)\t0.22331568324278164\n",
            "  (4, 20)\t0.22331568324278164\n",
            "  (4, 11)\t0.22331568324278164\n",
            "  (4, 33)\t0.22331568324278164\n",
            "  (4, 40)\t0.22331568324278164\n",
            "  (4, 24)\t0.22331568324278164\n",
            "  (4, 3)\t0.22331568324278164\n",
            "  (4, 4)\t0.3603393742607881\n",
            "  (4, 14)\t0.14955711571204908\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf_idf_array"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zlzxSTLfWhuq",
        "outputId": "92f10b50-2d4c-4030-e070-733b928562ec"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<5x52 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 58 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Array from Count Vectorizer \n",
        "cv_array = cv_vectorizer.fit_transform(clean_corpus)\n",
        "print(cv_array)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EfztBw6uO-rt",
        "outputId": "d5587b1c-5979-47fe-c71d-6edb1d495763"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  (0, 41)\t1\n",
            "  (0, 42)\t1\n",
            "  (0, 25)\t1\n",
            "  (0, 44)\t1\n",
            "  (1, 45)\t1\n",
            "  (1, 35)\t1\n",
            "  (1, 50)\t1\n",
            "  (1, 28)\t1\n",
            "  (1, 51)\t1\n",
            "  (1, 48)\t1\n",
            "  (1, 37)\t1\n",
            "  (1, 6)\t1\n",
            "  (1, 1)\t1\n",
            "  (1, 18)\t1\n",
            "  (1, 12)\t1\n",
            "  (1, 46)\t1\n",
            "  (1, 36)\t1\n",
            "  (2, 42)\t2\n",
            "  (2, 25)\t1\n",
            "  (2, 10)\t1\n",
            "  (2, 8)\t1\n",
            "  (2, 27)\t1\n",
            "  (2, 0)\t1\n",
            "  (2, 31)\t1\n",
            "  (2, 14)\t1\n",
            "  :\t:\n",
            "  (3, 22)\t1\n",
            "  (3, 30)\t1\n",
            "  (3, 32)\t1\n",
            "  (3, 4)\t1\n",
            "  (3, 19)\t1\n",
            "  (3, 23)\t1\n",
            "  (4, 14)\t1\n",
            "  (4, 4)\t2\n",
            "  (4, 3)\t1\n",
            "  (4, 24)\t1\n",
            "  (4, 40)\t1\n",
            "  (4, 33)\t1\n",
            "  (4, 11)\t1\n",
            "  (4, 20)\t1\n",
            "  (4, 9)\t1\n",
            "  (4, 47)\t1\n",
            "  (4, 13)\t1\n",
            "  (4, 15)\t1\n",
            "  (4, 21)\t1\n",
            "  (4, 26)\t1\n",
            "  (4, 38)\t1\n",
            "  (4, 17)\t1\n",
            "  (4, 2)\t1\n",
            "  (4, 34)\t1\n",
            "  (4, 5)\t1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cv_array"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kxl0oW9PWjSC",
        "outputId": "dbd9c672-8c7d-4623-ec0f-de5b40e6a12f"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<5x52 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 58 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating vocabulary array from tf-idf\n",
        "vocab_tf_idf = tf_idf_vectorizer.get_feature_names()\n",
        "print(vocab_tf_idf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cT2pj1zqPc03",
        "outputId": "a4f72d78-ea45-4038-d873-87283795cc8a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['amazon', 'beating', 'biology', 'blueberry', 'book', 'brain', 'championship', 'chill', 'cricket', 'dispenza’s', 'don’t', 'dr', 'eight', 'gamechanger', 'good', 'helped', 'however', 'impact', 'india', 'it’s', 'joe', 'learn', 'like', 'long', 'milkshake', 'movie', 'much', 'netflix', 'new', 'nice', 'paint', 'prime', 'read', 'reading', 'rewire', 'shopping', 'southampton', 'test', 'thought', 'time', 'try', 'want', 'watch', 'way', 'weekend', 'went', 'wicket', 'work', 'world', 'would', 'yesterday', 'zealand']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_tf_idf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iuammvrGWlNa",
        "outputId": "afb7584a-b6c6-4a50-8d95-1adbed0dfea4"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['amazon',\n",
              " 'beating',\n",
              " 'biology',\n",
              " 'blueberry',\n",
              " 'book',\n",
              " 'brain',\n",
              " 'championship',\n",
              " 'chill',\n",
              " 'cricket',\n",
              " 'dispenza’s',\n",
              " 'don’t',\n",
              " 'dr',\n",
              " 'eight',\n",
              " 'gamechanger',\n",
              " 'good',\n",
              " 'helped',\n",
              " 'however',\n",
              " 'impact',\n",
              " 'india',\n",
              " 'it’s',\n",
              " 'joe',\n",
              " 'learn',\n",
              " 'like',\n",
              " 'long',\n",
              " 'milkshake',\n",
              " 'movie',\n",
              " 'much',\n",
              " 'netflix',\n",
              " 'new',\n",
              " 'nice',\n",
              " 'paint',\n",
              " 'prime',\n",
              " 'read',\n",
              " 'reading',\n",
              " 'rewire',\n",
              " 'shopping',\n",
              " 'southampton',\n",
              " 'test',\n",
              " 'thought',\n",
              " 'time',\n",
              " 'try',\n",
              " 'want',\n",
              " 'watch',\n",
              " 'way',\n",
              " 'weekend',\n",
              " 'went',\n",
              " 'wicket',\n",
              " 'work',\n",
              " 'world',\n",
              " 'would',\n",
              " 'yesterday',\n",
              " 'zealand']"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating vocabulary array from cv\n",
        "vocab_cv = cv_vectorizer.get_feature_names()\n",
        "print(vocab_cv)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RwWb_F4zPlUu",
        "outputId": "7b0b63c2-0092-4b61-ee3b-2c8bc248b874"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['amazon', 'beating', 'biology', 'blueberry', 'book', 'brain', 'championship', 'chill', 'cricket', 'dispenza’s', 'don’t', 'dr', 'eight', 'gamechanger', 'good', 'helped', 'however', 'impact', 'india', 'it’s', 'joe', 'learn', 'like', 'long', 'milkshake', 'movie', 'much', 'netflix', 'new', 'nice', 'paint', 'prime', 'read', 'reading', 'rewire', 'shopping', 'southampton', 'test', 'thought', 'time', 'try', 'want', 'watch', 'way', 'weekend', 'went', 'wicket', 'work', 'world', 'would', 'yesterday', 'zealand']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_cv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gnbrv214WoGy",
        "outputId": "b4db468e-8163-4f5b-abb2-7b19f1a254a9"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['amazon',\n",
              " 'beating',\n",
              " 'biology',\n",
              " 'blueberry',\n",
              " 'book',\n",
              " 'brain',\n",
              " 'championship',\n",
              " 'chill',\n",
              " 'cricket',\n",
              " 'dispenza’s',\n",
              " 'don’t',\n",
              " 'dr',\n",
              " 'eight',\n",
              " 'gamechanger',\n",
              " 'good',\n",
              " 'helped',\n",
              " 'however',\n",
              " 'impact',\n",
              " 'india',\n",
              " 'it’s',\n",
              " 'joe',\n",
              " 'learn',\n",
              " 'like',\n",
              " 'long',\n",
              " 'milkshake',\n",
              " 'movie',\n",
              " 'much',\n",
              " 'netflix',\n",
              " 'new',\n",
              " 'nice',\n",
              " 'paint',\n",
              " 'prime',\n",
              " 'read',\n",
              " 'reading',\n",
              " 'rewire',\n",
              " 'shopping',\n",
              " 'southampton',\n",
              " 'test',\n",
              " 'thought',\n",
              " 'time',\n",
              " 'try',\n",
              " 'want',\n",
              " 'watch',\n",
              " 'way',\n",
              " 'weekend',\n",
              " 'went',\n",
              " 'wicket',\n",
              " 'work',\n",
              " 'world',\n",
              " 'would',\n",
              " 'yesterday',\n",
              " 'zealand']"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "display(\"Length of vocabulary array using tf_idf: \", len(vocab_tf_idf))\n",
        "display(\"Length of vocabulary array using cv: \",len(vocab_cv))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "b3Zw80VFPlRX",
        "outputId": "cfa0073b-6f19-4922-f21b-41f54f786dfb"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'Length of vocabulary array using tf_idf: '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "52"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'Length of vocabulary array using cv: '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "52"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. LDA Algorithm"
      ],
      "metadata": {
        "id": "tl1iIhCMPy1u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create object for the LDA class \n",
        "lda_algorithm = LatentDirichletAllocation(n_components = 6, max_iter = 20, random_state = 20)\n",
        "print(\"LDA Algorithm : \",lda_algorithm)\n",
        "# fit transform on model on our tf_idf_vectorizer\n",
        "X_topics = lda_algorithm.fit_transform(tf_idf_array)\n",
        "print(\"X Topics : \",X_topics)\n",
        "\n",
        "# .components_ gives us our topic distribution \n",
        "topic_words = lda_algorithm.components_\n",
        "print( 'Topic Words : ', topic_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R74KWBCEPlMe",
        "outputId": "b8c3aaf9-d5d5-46b1-e077-317acdb37f8d"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LDA Algorithm :  LatentDirichletAllocation(max_iter=20, n_components=6, random_state=20)\n",
            "X Topics :  [[0.05603663 0.05603398 0.71937475 0.056434   0.05603663 0.05608399]\n",
            " [0.03619889 0.81901639 0.03619418 0.03619616 0.03619889 0.03619549]\n",
            " [0.04471891 0.0447161  0.04487445 0.77619722 0.04471891 0.04477441]\n",
            " [0.03538801 0.03538454 0.03550291 0.03544894 0.03538801 0.82288759]\n",
            " [0.03142519 0.03142035 0.84281408 0.03145543 0.03142519 0.03145977]]\n",
            "Topic Words :  [[0.16667075 0.1666704  0.16667106 0.16667106 0.16667403 0.16667106\n",
            "  0.1666704  0.16667027 0.16667075 0.16667106 0.16667075 0.16667106\n",
            "  0.1666704  0.16667106 0.16668256 0.16667106 0.16667027 0.16667106\n",
            "  0.1666704  0.16667027 0.16667106 0.16667106 0.16667027 0.16667027\n",
            "  0.16667106 0.16668412 0.16667106 0.16667075 0.1666704  0.16667027\n",
            "  0.16667027 0.16667075 0.16667027 0.16667106 0.16667106 0.1666704\n",
            "  0.1666704  0.1666704  0.16667106 0.16667027 0.16667106 0.16667255\n",
            "  0.16667636 0.16667027 0.16667255 0.1666704  0.1666704  0.16667106\n",
            "  0.1666704  0.16667027 0.1666704  0.1666704 ]\n",
            " [0.1666695  0.44400184 0.16666971 0.16666971 0.16667177 0.16666971\n",
            "  0.44400184 0.16666917 0.1666695  0.16666971 0.1666695  0.16666971\n",
            "  0.44400184 0.16666971 0.16667769 0.16666971 0.16666917 0.16666971\n",
            "  0.44400184 0.16666917 0.16666971 0.16666971 0.16666917 0.16666917\n",
            "  0.16666971 0.16667877 0.16666971 0.1666695  0.44400184 0.16666917\n",
            "  0.16666917 0.1666695  0.16666917 0.16666971 0.16666971 0.44400184\n",
            "  0.44400184 0.44400184 0.16666971 0.16666917 0.16666971 0.16667075\n",
            "  0.16667339 0.16666917 0.16667075 0.44400184 0.44400184 0.16666971\n",
            "  0.44400184 0.16666917 0.44400184 0.44400184]\n",
            " [0.16666903 0.16666877 0.38996417 0.38996417 0.52711964 0.38996417\n",
            "  0.16666877 0.16666875 0.16666903 0.38996417 0.16666903 0.38996417\n",
            "  0.16666877 0.38996417 0.31602095 0.38996417 0.16666875 0.38996417\n",
            "  0.16666877 0.16666875 0.38996417 0.38996417 0.16666875 0.16666875\n",
            "  0.38996417 0.54722801 0.38996417 0.16666903 0.16666877 0.16666875\n",
            "  0.16666875 0.16666903 0.16666875 0.38996417 0.38996417 0.16666877\n",
            "  0.16666877 0.16666877 0.38996417 0.16666875 0.38996417 0.7346562\n",
            "  0.62424263 0.16666875 0.7346562  0.16666877 0.16666877 0.38996417\n",
            "  0.16666877 0.16666875 0.16666877 0.16666877]\n",
            " [0.50963368 0.16666946 0.16666998 0.16666998 0.16667223 0.16666998\n",
            "  0.16666946 0.1666694  0.50963368 0.16666998 0.50963368 0.16666998\n",
            "  0.16666946 0.16666998 0.39651361 0.16666998 0.1666694  0.16666998\n",
            "  0.16666946 0.1666694  0.16666998 0.16666998 0.1666694  0.1666694\n",
            "  0.16666998 0.39633158 0.16666998 0.50963368 0.16666946 0.1666694\n",
            "  0.1666694  0.50963368 0.1666694  0.16666998 0.16666998 0.16666946\n",
            "  0.16666946 0.16666946 0.16666998 0.1666694  0.16666998 0.16667128\n",
            "  0.72076146 0.1666694  0.16667128 0.16666946 0.16666946 0.16666998\n",
            "  0.16666946 0.1666694  0.16666946 0.16666946]\n",
            " [0.16667075 0.1666704  0.16667106 0.16667106 0.16667403 0.16667106\n",
            "  0.1666704  0.16667027 0.16667075 0.16667106 0.16667075 0.16667106\n",
            "  0.1666704  0.16667106 0.16668256 0.16667106 0.16667027 0.16667106\n",
            "  0.1666704  0.16667027 0.16667106 0.16667106 0.16667027 0.16667027\n",
            "  0.16667106 0.16668412 0.16667106 0.16667075 0.1666704  0.16667027\n",
            "  0.16667027 0.16667075 0.16667027 0.16667106 0.16667106 0.1666704\n",
            "  0.1666704  0.1666704  0.16667106 0.16667027 0.16667106 0.16667255\n",
            "  0.16667636 0.16667027 0.16667255 0.1666704  0.1666704  0.16667106\n",
            "  0.1666704  0.16667027 0.1666704  0.1666704 ]\n",
            " [0.1666695  0.16666923 0.16666971 0.16666971 0.39428703 0.16666971\n",
            "  0.16666923 0.448954   0.1666695  0.16666971 0.1666695  0.16666971\n",
            "  0.16666923 0.16666971 0.35574044 0.16666971 0.448954   0.16666971\n",
            "  0.16666923 0.448954   0.16666971 0.16666971 0.448954   0.448954\n",
            "  0.16666971 0.35555975 0.16666971 0.1666695  0.16666923 0.448954\n",
            "  0.448954   0.1666695  0.448954   0.16666971 0.16666971 0.16666923\n",
            "  0.16666923 0.16666923 0.16666971 0.448954   0.16666971 0.16667074\n",
            "  0.16667337 0.448954   0.16667074 0.16666923 0.16666923 0.16666971\n",
            "  0.16666923 0.448954   0.16666923 0.16666923]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.1) Retrieve the Topics"
      ],
      "metadata": {
        "id": "HJHEi1X4QDzW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the number of words \n",
        "n_top_words = 5\n",
        "for i, topic_list in enumerate (topic_words):\n",
        "\n",
        "  # Sorting an array or a list or the matrix according to their values\n",
        "  sorted_topic_list = np.argsort(topic_list)\n",
        "\n",
        "  # View the actual words present in those indexes\n",
        "  topic_words = np.array(vocab_tf_idf)[sorted_topic_list]\n",
        "\n",
        "  # topic_words variable contains the Topics and respective words present in those Topics\n",
        "  topic_words = topic_words[:-n_top_words:-1]\n",
        "\n",
        "  print (\"Topic\", str(i+1), topic_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WEcxxjtAQDU6",
        "outputId": "ae033605-2646-4c5a-e4a2-76d8ad395c1e"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic 1 ['movie' 'good' 'watch' 'book']\n",
            "Topic 2 ['zealand' 'test' 'beating' 'world']\n",
            "Topic 3 ['weekend' 'want' 'watch' 'movie']\n",
            "Topic 4 ['watch' 'amazon' 'cricket' 'don’t']\n",
            "Topic 5 ['movie' 'good' 'watch' 'book']\n",
            "Topic 6 ['however' 'chill' 'would' 'it’s']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.2) Annotate the Topic documents"
      ],
      "metadata": {
        "id": "C4v_5vZxQcOm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "document_topic = lda_algorithm.transform(tf_idf_array)\n",
        "\n",
        "for l in range(document_topic.shape[0]):\n",
        "  topic_document = document_topic[l].argmax()\n",
        "\n",
        "  print(\" Document \", l+1, \" --> Topic : \",topic_document )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hUlRvlzBQf_L",
        "outputId": "d940d166-a1e3-40ea-91b3-d75a6fc65119"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Document  1  --> Topic :  2\n",
            " Document  2  --> Topic :  1\n",
            " Document  3  --> Topic :  3\n",
            " Document  4  --> Topic :  5\n",
            " Document  5  --> Topic :  2\n"
          ]
        }
      ]
    }
  ]
}